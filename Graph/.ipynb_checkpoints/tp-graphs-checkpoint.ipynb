{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDI341: TP Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: Ce notebook a été conçu sous Python 2 et NetworkX version 1.11. De légers problèmes de compatibilité peuvent être rencontrés sous Python 3 (ex : urllib) et NetworkX 2.x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "import os.path\n",
    "import urllib\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : la documentation de NetworkX se trouve [ici](http://networkx.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de graphes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erdős-Rényi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par créer et visualiser un graphe de type Erdős-Rényi avec n=200 noeuds et p=0.04. Vous aurez besoin des fonctions `nx.erdos_renyi_graph` et `nx.draw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 200\n",
    "p = 0.04\n",
    "# G_erdos =\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculons des statistiques sur le nombre d'arêtes et la distribution des degrés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# degree_sequence_erdos = G_erdos.degree().values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trace la distribution des degrés en échelle normale, puis en échelle log-log. La fonction `nx.degree_histogram` vous sera utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# degree_freq = \n",
    "\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.plot(y, 'b-')\n",
    "# plt.ylabel(\"Frequence\")\n",
    "# plt.xlabel(\"Degre\")\n",
    "\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.loglog(y, 'b-')\n",
    "# plt.ylabel(\"log-Frequence\")\n",
    "# plt.xlabel(\"log-Degre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule maintenant le coefficient de clustering global (voir `nx.clustering`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche la longueur moyenne des plus courts chemins et le diamètre du graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barabási–Albert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée et visualise maintenant un graphe de Barabási–Albert avec n=200 noeuds (on ajoute à chaque fois m=3 arêtes), puis on applique la même analyse que celle faite pour Erdős-Rényi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 200\n",
    "m = 3\n",
    "# G_barabasi = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphe Karate Club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant travailler sur un graphe réel de petite taille (n=34, m=78) qui représente les liens d'amitié entre les adhérents d'un club de karaté (le graphe est intégré à la librairie `networkx`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=34\n",
    "G_karate = nx.karate_club_graph()\n",
    "\n",
    "# on définit une position des noeuds qui peut être ré-utilisée plusieurs fois\n",
    "# en appelant la fonction nx.draw avec l'option pos=pos\n",
    "pos = nx.spring_layout(G_karate)\n",
    "nx.draw(G_karate, cmap = plt.get_cmap('rainbow'), with_labels=True, pos=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va appliquer un clustering hiérarchique pour faire de la détection de communauté. On calcule d'abord la matrice des distances entre noeuds, où la distance entre 2 noeuds correspond à la longueur du plus court chemin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# le code suivant calcule une matrice de taille n x n\n",
    "# distances[i, j] contient la longueur du plus court chemin entre les noeuds i et j\n",
    "pcc_longueurs=nx.all_pairs_shortest_path_length(G_karate)\n",
    "distances=np.zeros((n,n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        distances[i, j] = pcc_longueurs[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant utiliser l'implémentation de clustering hiérarchique ascendant de `scikit-learn` avec le *lien moyen* comme mesure de dissimilarité entre clusters. On affiche tout d'abord le clustering à 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# TODO QUESTION 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va mettre en évidence visuellement les différences entre quelques mesures de centralité des noeuds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c_degree = \n",
    "# c_eigenvector = \n",
    "# c_closeness = \n",
    "# c_betweenness = \n",
    "\n",
    "# plt.figure(figsize=(18, 12))\n",
    "# f, axarr = plt.subplots(2, 2, num=1)\n",
    "# plt.sca(axarr[0,0])\n",
    "# nx.draw(G_karate, cmap = plt.get_cmap('jet'), node_color = c_degree, node_size=300, pos=pos, with_labels=True)\n",
    "# axarr[0,0].set_title('Centralite de degre', size=16)\n",
    "\n",
    "# plt.sca(axarr[0,1])\n",
    "# nx.draw(G_karate, cmap = plt.get_cmap('jet'), node_color = c_eigenvector, node_size=300, pos=pos, with_labels=True)\n",
    "# axarr[0,1].set_title('Centralite de vecteur propre', size=16)\n",
    "\n",
    "# plt.sca(axarr[1,0])\n",
    "# nx.draw(G_karate, cmap = plt.get_cmap('jet'), node_color = c_closeness, node_size=300, pos=pos, with_labels=True)\n",
    "# axarr[1,0].set_title('Centralite de proximite', size=16)\n",
    "\n",
    "# plt.sca(axarr[1,1])\n",
    "# nx.draw(G_karate, cmap = plt.get_cmap('jet'), node_color = c_betweenness, node_size=300, pos=pos, with_labels=True)\n",
    "# axarr[1,1].set_title('Centralite d\\'intermediarite', size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphe des produits Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9 (bonus +2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant étudier un graphe de grande taille dont les noeuds sont des produits vendus par Amazon, et deux noeuds sont connectés si les deux produits sont fréquemment achetés ensemble (plus de détails [ici](https://snap.stanford.edu/data/com-Amazon.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists('amazon.txt.gz') is False:\n",
    "    resp = urllib.urlretrieve('https://snap.stanford.edu/data/bigdata/' +\n",
    "                              'communities/com-amazon.ungraph.txt.gz', 'amazon.txt.gz')\n",
    "\n",
    "G_amazon = nx.read_edgelist('amazon.txt.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction dans les graphes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un *ego-network* est un sous-graphe d'un réseau social centré sur un utilisateur. Ici on va travailler avec un ego-network Facebook (téléchargeable [ici](https://snap.stanford.edu/data/egonets-Facebook.html)) qui représente les amis d'un utilisateur donné (sans ce dernier) et les liens d'amitié entre eux. Le jeu de données contient 10 ego-networks, on va travailler avec l'un d'entre eux seulement qui se prête bien à la visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists('facebook.tar.gz') is False:\n",
    "    resp = urllib.urlretrieve('https://snap.stanford.edu/data/facebook.tar.gz',\n",
    "                              'facebook.tar.gz')\n",
    "    tarfile.open(\"facebook.tar.gz\", 'r:gz').extractall('.')\n",
    "\n",
    "G_fb = nx.read_edgelist(\"facebook/414.edges\")\n",
    "n = G_fb.number_of_nodes()\n",
    "m = G_fb.number_of_edges()\n",
    "# on renumérote les noeuds de 0 à n-1\n",
    "mapping=dict(zip(G_fb.nodes(), range(n)))\n",
    "nx.relabel_nodes(G_fb, mapping, copy=False)\n",
    "pos = nx.spring_layout(G_fb)\n",
    "nx.draw(G_fb, node_size=200, pos=pos)\n",
    "print(\"Nombre de noeuds: %d\" % n)\n",
    "print(\"Nombre d'arêtes: %d\" % m)\n",
    "print(\"Nombre de composantes connexes: %d\" % nx.number_connected_components(G_fb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant essayer de prédire des liens dans le réseau. Pour cela, on commence par extraire une proportion des arêtes du graphe, dont on cherchera à prédire l'existence parmi toutes les arêtes non-existantes possibles. Le graphe d'apprentissage est le graphe original auquel on retire les arêtes sélectionnées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# G_fb_train est une copie du graphe original\n",
    "# auquel on a retiré 20% des arêtes choisies aléatoirement\n",
    "\n",
    "proportion_edges = 0.2\n",
    "edge_subset = random.sample(G_fb.edges(),\n",
    "                            int(proportion_edges * G_fb.number_of_edges()))\n",
    "G_fb_train = G_fb.copy()\n",
    "G_fb_train.remove_edges_from(edge_subset)\n",
    "\n",
    "edge_subset_size = len(list(edge_subset))\n",
    "print(\"Nombre d'arêtes retirées: %d\" % edge_subset_size)\n",
    "print(\"Nombre d'arêtes restantes: %d\" % (m - edge_subset_size))\n",
    "print(\"Nombre total d'arêtes non-existantes: %d\" %\n",
    "      len(list(nx.non_edges(G_fb_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut scorer les arêtes non-existantes de façon à ce que les arêtes réelles retirées aient un plus grand score. On utilise plusieurs mesures de similarité entre paires de noeud et on calcule l'Aire sous la Courbe ROC (AUC). On trace également les courbes ROC pour chaque similarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exemple qui génère les scores et les labels (vrai arête ou fausse arête) avec jaccard\n",
    "pred_jaccard = list(nx.jaccard_coefficient(G_fb_train))\n",
    "score_jaccard, label_jaccard = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in pred_jaccard])\n",
    "\n",
    "# afficher ROC curve et AUC\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_jaccard, tpr_jaccard, label='Coefficient de Jaccard - AUC %.2f' % auc_jaccard, linewidth=4)\n",
    "plt.plot(fpr_adamic, tpr_adamic, label='Index Adamic-Adar - AUC %.2f' % auc_adamic, linewidth=4)\n",
    "plt.plot(fpr_pref, tpr_pref, label='Attachement preferentiel - AUC %.2f' % auc_pref, linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrai positifs')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant faire de la classification semi-supervisée des noeuds. Pour cela on va utiliser les attributs qui sont fournis avec l'ego-network. Ces attributs représentent des caractéristiques (anonymisées) des utilisateurs du réseau. Dans la suite nous allons utiliser l'attribut `43` qui vaut `+1` (rouge) si la personne a étudié dans une école donnée, et `-1` (bleu) sinon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on charge les labels des noeuds et on les affiche\n",
    "\n",
    "with open('facebook/414.featnames') as f:\n",
    "    for i, l in enumerate(f):\n",
    "        pass\n",
    "\n",
    "n_feat = i+1\n",
    "\n",
    "features = np.zeros((n, n_feat))\n",
    "f = open('facebook/414.feat', 'r')\n",
    "for line in f:\n",
    "    if line.split()[0] in mapping:\n",
    "        node_id = mapping[line.split()[0]]\n",
    "        features[node_id, :] = list(map(int, line.split()[1:]))\n",
    "\n",
    "features = 2*features-1\n",
    "feat_id = 43\n",
    "labels = features[:, feat_id]\n",
    "\n",
    "nx.draw(G_fb, cmap = plt.get_cmap('bwr'), nodelist=range(n), node_color = labels, node_size=200, pos=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que cet attribut est relativement lisse sur le graphe, il se prête donc bien à la classification par propagation de label (ce n'est pas le cas de tous les attributs!). On va donc sélectionner aléatoirement une petite proportion de noeuds pour lesquels nous aurons accès aux labels. Notre tâche sera d'utiliser ces noeuds étiquetés ainsi que la structure du graphe pour prédire le label des autres noeuds. On regarde d'abord les noeuds étiquetés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on sélectionne 20% des noeuds pour lesquels on a accès à l'étiquette\n",
    "\n",
    "random.seed(5)\n",
    "proportion_nodes = 0.2\n",
    "labeled_nodes = random.sample(G_fb.nodes(), int(proportion_nodes * G_fb.number_of_nodes()))\n",
    "\n",
    "known_labels = np.zeros(n)\n",
    "known_labels[labeled_nodes] = labels[labeled_nodes]\n",
    "\n",
    "nx.draw(G_fb, cmap = plt.get_cmap('bwr'), nodelist=range(n), node_color = known_labels, node_size=200, pos=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant appliquer la propagation de label et voir les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.7\n",
    "L_sym = nx.normalized_laplacian_matrix(G_fb)\n",
    "\n",
    "# on calcule la matrice de labels initiale\n",
    "Y = np.zeros((n,2))\n",
    "Y[known_labels==-1, 0] = 1\n",
    "Y[known_labels==1, 1] = 1\n",
    "\n",
    "# propagation de labels à faire ici\n",
    "\n",
    "# labels prédits à mettre dans une variable F_pred pour affichage ci-dessous\n",
    "# F_pred = \n",
    "# taux de succes a mettre dans une variable pred pour affichage ci-dessous\n",
    "# pred = \n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "f, axarr = plt.subplots(1, 2, num=1)\n",
    "plt.sca(axarr[0])\n",
    "nx.draw(G_fb, cmap = plt.get_cmap('bwr'), nodelist=range(n), node_color = labels, node_size=200, pos=pos)\n",
    "axarr[0].set_title('Vrais labels', size=16)\n",
    "plt.sca(axarr[1])\n",
    "nx.draw(G_fb, cmap = plt.get_cmap('bwr'), nodelist=range(n), node_color = F_pred, node_size=200, pos=pos)\n",
    "axarr[1].set_title('Labels predits (taux de succes: %.2f)' % pred, size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
